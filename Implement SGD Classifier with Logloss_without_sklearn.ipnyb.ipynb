{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eiDWcM_MC3H"
   },
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfe2NTQtLq11"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "# please don't change random_state\n",
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "# make_classification is used to create custom dataset \n",
    "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8W2fg1cyGdX",
    "outputId": "80fbb63d-0ecf-43af-cfc1-0fb6e2dd8c5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gONY1YiDq7jD"
   },
   "outputs": [],
   "source": [
    "# Standardizing the data.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DR_YMBsyOci",
    "outputId": "d5647b56-0902-4e23-bc68-8972403f0775"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HpvTwDHyQQy",
    "outputId": "110ecc5f-f080-40cb-db6a-04d75a312957"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYaVyQ2lyXcr",
    "outputId": "8cb95da1-e88f-47c1-f261-09fc0db6f93a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.70, NNZs: 15, Bias: -0.501317, T: 37500, Avg. loss: 0.552526\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.752393, T: 75000, Avg. loss: 0.448021\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.26, NNZs: 15, Bias: -0.902742, T: 112500, Avg. loss: 0.415724\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.43, NNZs: 15, Bias: -1.003816, T: 150000, Avg. loss: 0.400895\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.55, NNZs: 15, Bias: -1.076296, T: 187500, Avg. loss: 0.392879\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.65, NNZs: 15, Bias: -1.131077, T: 225000, Avg. loss: 0.388094\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.73, NNZs: 15, Bias: -1.171791, T: 262500, Avg. loss: 0.385077\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.80, NNZs: 15, Bias: -1.203840, T: 300000, Avg. loss: 0.383074\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.86, NNZs: 15, Bias: -1.229563, T: 337500, Avg. loss: 0.381703\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.90, NNZs: 15, Bias: -1.251245, T: 375000, Avg. loss: 0.380763\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.94, NNZs: 15, Bias: -1.269044, T: 412500, Avg. loss: 0.380084\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.98, NNZs: 15, Bias: -1.282485, T: 450000, Avg. loss: 0.379607\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2.01, NNZs: 15, Bias: -1.294386, T: 487500, Avg. loss: 0.379251\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 2.03, NNZs: 15, Bias: -1.305805, T: 525000, Avg. loss: 0.378992\n",
      "Total training time: 0.27 seconds.\n",
      "Convergence after 14 epochs took 0.27 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EAfkVI6GyaRO",
    "outputId": "e0263932-c67e-418d-aec4-4f1e651a327e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.89007184,  0.63162363, -0.07594145,  0.63107107, -0.38434375,\n",
       "          0.93235243, -0.89573521, -0.07340522,  0.40591417,  0.4199991 ,\n",
       "          0.24722143,  0.05046199, -0.08877987,  0.54081652,  0.06643888]]),\n",
       " (1, 15),\n",
       " array([-1.30580538]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-CcGTKgsMrY"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1_8bdzitDlM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1.  We will be giving you some functions, please write code in that functions only.\n",
    "\n",
    "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zU2Y3-FQuJ3z"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (1,dim) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "    w = np.zeros_like(dim)\n",
    "    b = 0\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7I6uWBRsKc4",
    "outputId": "a31ec191-915f-4eba-9fc1-2a8ce48d2c1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "print('w =',(w))\n",
    "print('b =',str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MI5SAjP9ofN"
   },
   "source": [
    "<font color='cyan'>Grader function - 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pv1llH429wG5",
    "outputId": "cd99555b-0b1e-4aa5-9fbb-81867620538a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "def grader_weights(w,b):\n",
    "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
    "  return True\n",
    "grader_weights(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "    return (1/(1+np.exp(-(z))))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YrGDwg3Ae4m"
   },
   "source": [
    "<font color='cyan'>Grader function - 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_JASp_NAfK_",
    "outputId": "50b454e1-91f4-4aed-f92c-0e9b9588bc44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "  val=sigmoid(z)\n",
    "  assert(val==0.8807970779778823)\n",
    "  return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VaFDgsp3sKi6"
   },
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    loss=0\n",
    "    n = len(y_true)\n",
    "    for i in range(n):\n",
    "        loss+=((y_true[i]*math.log10(y_pred[i]))+((1-y_true[i])*math.log10(1-y_pred[i])))\n",
    "    logloss=-1*(1/n)*loss\n",
    "    return logloss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs1BTXVSClBt"
   },
   "source": [
    "<font color='cyan'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzttjvBFCuQ5",
    "outputId": "6b9c9c57-b359-41b9-efbe-c6a908816de6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_logloss(true,pred):\n",
    "  loss=logloss(true,pred)\n",
    "  assert(loss==0.07644900402910389)\n",
    "  return True\n",
    "true=[1,1,0,1,0]\n",
    "pred=[0.9,0.8,0.1,0.8,0.2]\n",
    "grader_logloss(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    dw = x*(y-sigmoid(np.dot(w.T,x)+b)) - ((alpha*w)/N)\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUFLNqL_GER9"
   },
   "source": [
    "<font color='cyan'>Grader function - 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WI3xD8ctGEnJ",
    "outputId": "589a3f7e-846d-4411-daa8-cf58e7e20f61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_dw(x,y,w,b,alpha,N):\n",
    "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
    "  assert(np.sum(grad_dw)==2.613689585)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0nUf2ft4EZp8"
   },
   "outputs": [],
   "source": [
    " def gradient_db(x,y,w,b):\n",
    "     '''In this function, we will compute gradient w.r.to b '''\n",
    "     db  = y-sigmoid(np.dot(w.T,x)+b)\n",
    "     return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbcBzufVG6qk"
   },
   "source": [
    "<font color='cyan'>Grader function - 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfFDKmscG5qZ",
    "outputId": "8bc982a1-ae30-4af5-b66b-0c48c818c579"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x,y,w,b):\n",
    "  grad_db=gradient_db(x,y,w,b)\n",
    "  assert(grad_db==-0.5)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_db(grad_x,grad_y,grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "dmAdc5ejEZ25"
   },
   "outputs": [],
   "source": [
    "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    #Here eta0 is learning rate\n",
    "    #implement the code as follows\n",
    "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
    "    w,b = initialize_weights(X_train[0])\n",
    "    loss_test = []\n",
    "    loss_train = []\n",
    "    epoc = []\n",
    "    N = len(X_train)\n",
    "    # for every epoch\n",
    "    for i in range(0,epochs):\n",
    "        # for every data point(X_train,y_train)\n",
    "        for j in range(0,N):\n",
    "           #compute gradient w.r.to w (call the gradient_dw() function)\n",
    "           grad_dw=gradient_dw(X_train[j],y_train[j],w,b,alpha,N)\n",
    "           #compute gradient w.r.to b (call the gradient_db() function)\n",
    "           grad_db=gradient_db(X_train[j],y_train[j],w,b)\n",
    "           #update w, b\n",
    "           w=np.array(w)+(eta0*(np.array(grad_dw)))\n",
    "           b=b+(eta0*(grad_db))\n",
    "        # predict the output of x_train[for all data points in X_train] using w,b\n",
    "        z = np.dot(X_train,w.T)+b\n",
    "        print(z)\n",
    "        y_pred = sigmoid(z)\n",
    "    #compute the loss between predicted and actual values (call the loss function)\n",
    "        train_ls = logloss(y_train,y_pred)\n",
    "    # store all the train loss values in a list\n",
    "        loss_train.append(train_ls)\n",
    "    # predict the output of x_test[for all data points in X_test] using w,b\n",
    "        z = np.dot(X_test,w.T)+b\n",
    "        y_pred_test = sigmoid(z)\n",
    "    #compute the loss between predicted and actual values (call the loss function)\n",
    "        test_ls = logloss(y_test,y_pred_test)\n",
    "    # store all the test loss values in a list\n",
    "        loss_test.append(test_ls)\n",
    "\n",
    "        epoc.append(i)\n",
    "        # you can also compare previous loss and current loss, if loss is not updating then stop the process and return w,b\n",
    "\n",
    "    return w,b, loss_train, loss_test,epoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUquz7LFEZ6E",
    "outputId": "d6166372-98bc-4091-d43c-6b2fd0aaa9b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8100148  -1.46546125 -0.93348888 ...  0.6839015  -1.33785984\n",
      "  0.00888405]\n",
      "[-1.1716379  -2.21382945 -1.29698533 ...  1.09219261 -1.9525598\n",
      " -0.10213406]\n",
      "[-1.38203215 -2.69935917 -1.50443073 ...  1.37632101 -2.33506969\n",
      " -0.16675903]\n",
      "[-1.51875177 -3.04710034 -1.64313939 ...  1.58974244 -2.5986879\n",
      " -0.20115781]\n",
      "[-1.61370039 -3.31009941 -1.74372966 ...  1.75652673 -2.79087074\n",
      " -0.21929304]\n",
      "[-1.68275041 -3.51604291 -1.82032639 ...  1.89007294 -2.93632844\n",
      " -0.22860371]\n",
      "[-1.73471648 -3.68123334 -1.88058156 ...  1.99882903 -3.04946718\n",
      " -0.23297174]\n",
      "[-1.77487737 -3.81607446 -1.92908834 ...  2.0885284  -3.1393235\n",
      " -0.23450461]\n",
      "[-1.8065775  -3.92760428 -1.96880833 ...  2.16325115 -3.21187389\n",
      " -0.23440072]\n",
      "[-1.83203165 -4.02080022 -2.00175626 ...  2.2259999  -3.27123516\n",
      " -0.23336812]\n",
      "[-1.85276021 -4.09930749 -2.02936169 ...  2.27904173 -3.3203369\n",
      " -0.23183626]\n",
      "[-1.86983872 -4.16587158 -2.05267405 ...  2.32412401 -3.36132046\n",
      " -0.23006919]\n",
      "[-1.88404776 -4.22260825 -2.07248548 ...  2.36261682 -3.39578681\n",
      " -0.22822936]\n",
      "[-1.8959665  -4.27117905 -2.08940783 ...  2.39561016 -3.42495636\n",
      " -0.22641536]\n",
      "[-1.90603317 -4.31290958 -2.10392282 ...  2.4239821  -3.44977524\n",
      " -0.22468501]\n"
     ]
    }
   ],
   "source": [
    "alpha=0.0001\n",
    "eta0=0.0001\n",
    "N=len(X_train)\n",
    "epochs=15\n",
    "w,b, loss_train, loss_test,epoc=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "<font color='red'>Goal of assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nx8Rs9rfEZ1R",
    "outputId": "920be371-b785-4cca-9ae6-a275955aecec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.01475437,  0.01493816, -0.00227909,  0.00670554, -0.00641395,\n",
       "          0.01189447, -0.00725785,  0.00180162,  0.00978705,  0.00360839,\n",
       "          0.00457525,  0.00349702,  0.00054823,  0.00292799,  0.00056488]]),\n",
       " array([-0.00611698]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
    "\n",
    "* epoch number on X-axis\n",
    "* loss on Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "1O6GrRt7UeCJ",
    "outputId": "3a343158-8950-4285-83a0-06397c886846"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16436073400>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.grid()\n",
    "plt.plot(epoc,loss_train, label='tain log loss')\n",
    "plt.plot(epoc,loss_test, label='test log loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FUN8puFoEZtU",
    "outputId": "68115e29-c202-4a78-8950-782e6b679841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.02584\n",
      "1.02352\n"
     ]
    }
   ],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
    "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-k28U1xDsLIO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMokBfs3-2PY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
